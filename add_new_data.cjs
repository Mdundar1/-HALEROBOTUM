const fs = require('fs');
const path = require('path');

// Paths
const DATASET_PATH = path.join(__dirname, 'server', 'dataset.json');
const NEW_DATA_PATH = path.join(__dirname, 'test_new_data.json');

// Load existing dataset
console.log('ğŸ“‚ Mevcut dataset yÃ¼kleniyor...');
const existingDataset = JSON.parse(fs.readFileSync(DATASET_PATH, 'utf-8'));
console.log(`âœ“ Mevcut dataset: ${existingDataset.length} kayÄ±t`);

// Load new data
console.log('\nğŸ“‚ Yeni veriler yÃ¼kleniyor...');
const newData = JSON.parse(fs.readFileSync(NEW_DATA_PATH, 'utf-8'));
console.log(`âœ“ Yeni veriler: ${newData.length} kayÄ±t`);

// Check for duplicates
const existingCodes = new Set(existingDataset.map(item => item.code));
let duplicateCount = 0;
let addedCount = 0;

const itemsToAdd = [];

newData.forEach((item, idx) => {
    if (existingCodes.has(item.code)) {
        duplicateCount++;
        console.log(`âš  Duplicate bulundu: ${item.code}`);
    } else {
        const newItem = {
            id: `${Date.now()}-${idx}`,
            code: item.code,
            description: item.description,
            unit: item.unit,
            unitPrice: item.unitPrice
        };
        itemsToAdd.push(newItem);
        existingCodes.add(item.code);
        addedCount++;
    }
});

// Add new items
if (itemsToAdd.length > 0) {
    const updatedDataset = [...existingDataset, ...itemsToAdd];

    // Save updated dataset
    fs.writeFileSync(DATASET_PATH, JSON.stringify(updatedDataset, null, 2), 'utf-8');
    console.log(`\nâœ“ Dataset gÃ¼ncellendi!`);
    console.log(`  - Eklenen kayÄ±t: ${addedCount}`);
    console.log(`  - Atlanan duplicate: ${duplicateCount}`);
    console.log(`  - Toplam kayÄ±t: ${updatedDataset.length}`);
} else {
    console.log(`\nâš  HiÃ§bir yeni kayÄ±t eklenmedi. TÃ¼m kayÄ±tlar zaten mevcut (${duplicateCount} duplicate)`);
}
